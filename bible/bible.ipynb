{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Configurations de base du projet:\n",
    "la langue pour laquelle on souhaite reccuperer la bible ainsique les differents livres de la bible qui existe\n",
    "\n",
    "_gen1_ represente le premier livre de la Genèse\n",
    "C'est le livre par defaut du site\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par chercher tous les id de livres, pour cela on cherche juste les valuers des attributs _`data-vars-event-label`_ des elements selectionnés par _`ul.list.ma0.pa0.bg-white.pb5.min-vh-100 li`_ ceci sera fait grace à la console du navigateur puis on mettra le resultat dans un fichier json _utils/livres.json_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langue dans laquelle on va travailler\n",
    "lang = 63  # bible en Haussa avec caractères type arabique\n",
    "\n",
    "VERSE_SELECTOR = \".yv-gray50.lh-copy.f3-m\"\n",
    "\n",
    "# fichier de sauvegardes des sessions\n",
    "SESSIONS_PATH = os.path.join(os.getcwd(), 'sessions.json')\n",
    "\n",
    "\n",
    "# dossier dans lequel on va mettre les dossiers chaque chapitre pour cette langue\n",
    "def get_lang_folder_path(lang: int = lang) -> str:\n",
    "    path = os.path.join(os.getcwd(), f\"/data/{lang}\")\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "# dossier dans lequel on va mettre les fichiers txt pour chaqe chap du livre livre\n",
    "def get_book_folder_path_for_lang(book: str, lang: int = lang) -> str:\n",
    "    path = os.path.join(os.getcwd(), f\"data/{lang}/{book}\").replace('\\\\', '/')\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(f'Path to saves folder created : {path} ')\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "\n",
    "# chargeons les livres\n",
    "with open('utils/livres.json', 'r') as books_file:\n",
    "    books = json.load(books_file)\n",
    "\n",
    "# 1er chapoitre du livre de la genese dans la langue en cours\n",
    "gen1 = requests.get(f\"https://www.bible.com/bible/{lang}/GEN.1.NFC\")\n",
    "\n",
    "\n",
    "def chapter_link(chapter: str, lang: int = lang) -> str:\n",
    "    return f\"https://www.bible.com/bible/{lang}/{chapter}\"\n",
    "\n",
    "\n",
    "def verse_link(chapter: str, verse: int, lang: int = lang) -> str:\n",
    "    return f\"https://www.bible.com/bible/{lang}/{chapter}.{verse}\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La methode qui nous permettra d'effectuer nos requettes au serveur afin d'obtenir les differentes ressources dont on aura besoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(url: str):\n",
    "    fetched, try_count = False, 0\n",
    "    def wait_time(count=try_count) -> int: return 5 if count < 10 else 10\n",
    "    while not fetched:\n",
    "        try:\n",
    "            res = requests.get(url, timeout=15)\n",
    "        except Exception as e:\n",
    "            print('Request Failed please, check your internet connexion')\n",
    "            try_count += 1\n",
    "            if try_count > 5:\n",
    "                print(f'Automatic retry in {wait_time()} secs .....')\n",
    "                time.sleep(wait_time())\n",
    "        else:\n",
    "            fetched = True\n",
    "            return res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour trouver les differents chapitres d'un livres, nous exploiterons une API presente sur le site, elle nous permettra à partir du numero de la langue et de l'id du livre, d'obtenir les id de tous les chapitres contenus dans ce livre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les urls des json des chapitres pour la langue en cours\n",
    "chapters_url = f\"https://www.bible.com/json/bible/books/{lang}\"\n",
    "chapters: dict[list] = {}\n",
    "print(\"Looking for chapters of each book of the bible\")\n",
    "not_founds = 0\n",
    "for book in books:\n",
    "\n",
    "    res = fetch(f\"{chapters_url}/{book}/chapters\")\n",
    "    if res.status_code == 500:\n",
    "        print(f\"[{book}] Not Found ..\")\n",
    "        not_founds += 1\n",
    "        continue\n",
    "    chapters[book] = []\n",
    "    data = json.loads(res.content)\n",
    "    for item in data['items']:\n",
    "        chapters[book].append(item['usfm'])\n",
    "\n",
    "    print(f\"[{book}] Completed ..\")\n",
    "\n",
    "print(\n",
    "    f\"\\n\\n\\n[{lang}] Chapter titles fetched with success, {not_founds} books not found\")\n",
    "chapters\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder les de chapitres par langue dans chaque langue aura un fichier json dans lequel on mettre un dicco.\n",
    "Le dossier `./utils/chapitres_id/` contiendra des fichiers json pour chaque langue, chaque fichier contiendra tous les id de chapitres rangés par livre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_id_file = os.path.join(\n",
    "    os.getcwd(), f'utils/chapitres_id').replace('\\\\', '/')\n",
    "if not os.path.exists(chapters_id_file):\n",
    "    os.makedirs(chapters_id_file)\n",
    "with open(f'{chapters_id_file}/{lang}.json', 'w', encoding='utf-8') as lang_chaps_file:\n",
    "    json.dump(chapters, lang_chaps_file, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction qui nous permettra de mettre à jour un fichier json, qu'il soit de type `dictionnaire` ou `liste`, on utilisera cela pour les sauvegardes de sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json_file(data,  file_path: str, type: type = list, lang: int = lang):\n",
    "    path = os.path.join(os.getcwd(), file_path)\n",
    "    # initializing the file if not exists\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, 'w', encoding='utf-8') as file:\n",
    "            file.write('[]') if type == list else file.write('{}')\n",
    "    # getting the data in the file and updating it\n",
    "    with open(path, 'r+', encoding='utf-8') as file:\n",
    "        file_data = json.load(file)\n",
    "        if type == list:  # si nous sommes dans un liste\n",
    "            file_data.append(data)\n",
    "        else:  # si c'est un dictionnaire plutot\n",
    "            file_data[f'{lang}'] = data\n",
    "    # write the final data in the file\n",
    "    with open(path, 'w', encoding='utf-8') as file:     \n",
    "        json.dump(file_data, file, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementons les fonctions de sauvegarde et de reprise de sessions afin de pourvoir reprendre un scraping qui s'arrete de facon impromptue. Ces sauvegardes de sessions se feront en separant les langues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_book': 'GEN', 'last_chapter': 'GEN.35', 'completed_books': []}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def save_current_session(book: str, chapter: str, completed_books: list[str], lang: int = lang):\n",
    "\n",
    "    session = {\n",
    "        \"last_book\": book,\n",
    "        \"last_chapter\": chapter,\n",
    "        \"completed_books\": completed_books\n",
    "    }\n",
    "    update_json_file(session, SESSIONS_PATH, dict)\n",
    "\n",
    "\n",
    "def load_last_session(lang: int = lang):\n",
    "    default_session = {\n",
    "        \"last_book\": '',\n",
    "        \"last_chapter\": '',\n",
    "        \"completed_books\": []\n",
    "    }\n",
    "    if not os.path.exists(SESSIONS_PATH):\n",
    "        with open(SESSIONS_PATH, 'w', encoding='utf-8') as sessions_file:\n",
    "            json.dump({lang: default_session}, sessions_file, indent=4)\n",
    "        return default_session\n",
    "\n",
    "    with open(SESSIONS_PATH, 'r', encoding='utf-8') as sessions_file:\n",
    "        sessions = json.load(sessions_file)\n",
    "        try:\n",
    "            return sessions[f'{lang}']\n",
    "        except KeyError:\n",
    "            return default_session\n",
    "\n",
    "\n",
    "def json_print(message, json_doc):\n",
    "    print(message)\n",
    "    print(json.dumps(json_doc, indent=4, separators=(',', ': ')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading last scraping session ...\n",
      "The last session was:\n",
      "{\n",
      "    \"last_book\": \"GEN\",\n",
      "    \"last_chapter\": \"GEN.50\",\n",
      "    \"completed_books\": [\n",
      "        \"GEN\"\n",
      "    ]\n",
      "}\n",
      "[EXO] Proceeding book ...\n",
      "[EXO.1] Proceeding chapter...\n",
      "[EXO.1][1] Verse fetched with success\n",
      "[EXO.1][2] Verse fetched with success\n",
      "[EXO.1][3] Verse fetched with success\n",
      "[EXO.1][4] Verse fetched with success\n",
      "[EXO.1][5] Verse fetched with success\n",
      "[EXO.1][6] Verse fetched with success\n",
      "[EXO.1][7] Verse fetched with success\n",
      "[EXO.1][8] Verse fetched with success\n",
      "[EXO.1][9] Verse fetched with success\n",
      "[EXO.1][10] Verse fetched with success\n",
      "[EXO.1][11] Verse fetched with success\n",
      "[EXO.1][12] Verse fetched with success\n",
      "[EXO.1][13] Verse fetched with success\n",
      "[EXO.1][14] Verse fetched with success\n",
      "[EXO.1][15] Verse fetched with success\n",
      "[EXO.1][16] Verse fetched with success\n",
      "[EXO.1][17] Verse fetched with success\n",
      "[EXO.1][18] Verse fetched with success\n",
      "[EXO.1][19] Verse fetched with success\n",
      "[EXO.1][20] Verse fetched with success\n",
      "[EXO.1][21] Verse fetched with success\n",
      "[EXO.1][22] Verse fetched with success\n",
      "Path to saves folder created : c:/workspace/mlpc/lang_translation/data_colecting/bible/data/63/EXO \n",
      "[EXO.1] done\n",
      "[EXO.2] Proceeding chapter...\n",
      "[EXO.2][1] Verse fetched with success\n",
      "[EXO.2][2] Verse fetched with success\n",
      "[EXO.2][3] Verse fetched with success\n",
      "[EXO.2][4] Verse fetched with success\n",
      "[EXO.2][5] Verse fetched with success\n",
      "[EXO.2][6] Verse fetched with success\n",
      "[EXO.2][7] Verse fetched with success\n",
      "[EXO.2][8] Verse fetched with success\n",
      "[EXO.2][9] Verse fetched with success\n",
      "[EXO.2][10] Verse fetched with success\n",
      "[EXO.2][11] Verse fetched with success\n",
      "[EXO.2][12] Verse fetched with success\n",
      "[EXO.2][13] Verse fetched with success\n",
      "[EXO.2][14] Verse fetched with success\n",
      "[EXO.2][15] Verse fetched with success\n",
      "[EXO.2][16] Verse fetched with success\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m# commencer à cchercher les versets duc chapitre du livre dans lequel on est\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     verse_res \u001b[39m=\u001b[39m fetch(verse_link(chapter, verse_index))\n\u001b[0;32m     30\u001b[0m     \u001b[39m# si le verset n'existe pas on sera redirigé vers la page du chapitre\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(verse_res\u001b[39m.\u001b[39mcontent, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mfetch\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m fetched:\n\u001b[0;32m      5\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m         res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, timeout\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m      8\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRequest Failed please, check your internet connexion\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\requests\\api.py:75\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39m\u001b[39mget\u001b[39m\u001b[39m'\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\requests\\sessions.py:542\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    537\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    538\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    539\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[0;32m    540\u001b[0m }\n\u001b[0;32m    541\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 542\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    544\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\requests\\sessions.py:697\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[1;32m--> 697\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[0;32m    699\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\requests\\models.py:836\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    834\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    835\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 836\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    838\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\requests\\models.py:758\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    757\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    759\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[0;32m    760\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\urllib3\\response.py:624\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m--> 624\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[0;32m    625\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[0;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\urllib3\\response.py:831\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    830\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 831\u001b[0m chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_chunk(amt)\n\u001b[0;32m    832\u001b[0m decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(\n\u001b[0;32m    833\u001b[0m     chunk, decode_content\u001b[39m=\u001b[39mdecode_content, flush_decoder\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    834\u001b[0m )\n\u001b[0;32m    835\u001b[0m \u001b[39mif\u001b[39;00m decoded:\n",
      "File \u001b[1;32mc:\\workspace\\mlpc\\lang_translation\\data_colecting\\venv\\lib\\site-packages\\urllib3\\response.py:784\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    782\u001b[0m     returned_chunk \u001b[39m=\u001b[39m value\n\u001b[0;32m    783\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# amt > self.chunk_left\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m     returned_chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49m_safe_read(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_left)\n\u001b[0;32m    785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39m_safe_read(\u001b[39m2\u001b[39m)  \u001b[39m# Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Anaconda\\lib\\http\\client.py:626\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    624\u001b[0m s \u001b[39m=\u001b[39m []\n\u001b[0;32m    625\u001b[0m \u001b[39mwhile\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 626\u001b[0m     chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(\u001b[39mmin\u001b[39;49m(amt, MAXAMOUNT))\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunk:\n\u001b[0;32m    628\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(s), amt)\n",
      "File \u001b[1;32mC:\\Programs\\Anaconda\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Programs\\Anaconda\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mC:\\Programs\\Anaconda\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Loading last scraping session ...\")\n",
    "last_session = load_last_session()\n",
    "json_print('The last session was:', last_session)\n",
    "\n",
    "completed_books = last_session['completed_books']\n",
    "last_chapter = last_session['last_chapter']\n",
    "last_book = last_session['last_book']\n",
    "\n",
    "for book_name in chapters:\n",
    "    if book_name in completed_books:\n",
    "        continue\n",
    "    book = chapters[book_name]\n",
    "    print(f'[{book_name}] Proceeding book ...')\n",
    "\n",
    "    for chapter in book:\n",
    "\n",
    "        if book_name == last_book and int(chapter.split('.')[1]) <= int(last_chapter.split('.')[1]):\n",
    "            continue\n",
    "\n",
    "        print(f'[{chapter}] Proceeding chapter...')\n",
    "        # selectionner un chapitre ainsi que sa page/url\n",
    "        chapter_res = fetch(chapter_link(chapter))\n",
    "        # les versets du chapitre\n",
    "        chapter_verses: list[str] = []\n",
    "\n",
    "        verse_index = 1\n",
    "        # commencer à cchercher les versets duc chapitre du livre dans lequel on est\n",
    "        while True:\n",
    "            verse_res = fetch(verse_link(chapter, verse_index))\n",
    "            # si le verset n'existe pas on sera redirigé vers la page du chapitre\n",
    "            soup = BeautifulSoup(verse_res.content, 'html.parser')\n",
    "            verses = soup.select(VERSE_SELECTOR)\n",
    "            if verse_res.url == chapter_res.url or verse_res.url == gen1.url or len(verses) == 0:\n",
    "                break\n",
    "\n",
    "            chapter_verses.append(verses[0].text.replace('\\n', ' '))\n",
    "            print(f\"[{chapter}][{verse_index}] Verse fetched with success\")\n",
    "            verse_index += 1\n",
    "\n",
    "        folder = get_book_folder_path_for_lang(book_name)\n",
    "\n",
    "        with open(f'{folder}/{chapter}.txt', mode='w', encoding='utf-8') as verse_output_file:\n",
    "            for verse in chapter_verses:\n",
    "                verse.replace('\\n', ' ')\n",
    "                verse_output_file.write(verse.strip() + '\\n')\n",
    "\n",
    "        save_current_session(book_name, chapter, completed_books)\n",
    "        print(f'[{chapter}] done')\n",
    "\n",
    "    completed_books.append(book_name)\n",
    "    save_current_session(book_name, chapter, completed_books)\n",
    "    print(f'[{book_name}] done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e9ebd3ff607729a7cbb3fb982ffff5cbd5fec53b6fd8f66a267c1cebcfbfd48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
